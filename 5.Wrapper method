import numpy as np
import random
from sklearn.preprocessing import RobustScaler
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import joblib
import pandas as pd
import scipy.stats as stats

# Set global random seed
RANDOM_SEED = 42

def set_global_random_seed(seed):
    np.random.seed(seed)
    random.seed(seed)

set_global_random_seed(RANDOM_SEED)

def scale_columns_with_robust_scaler(data, scaler=None):
    if scaler is None:
        scaler = RobustScaler()
        scaled_data = scaler.fit_transform(data)
    else:
        scaled_data = scaler.transform(data)
    return scaled_data, scaler

def calculate_confidence_intervals(metric_values, confidence=0.95):
    n = len(metric_values)
    mean = np.mean(metric_values)
    se = stats.sem(metric_values)
    h = se * stats.t.ppf((1 + confidence) / 2., n-1)
    return mean - h, mean + h

def calculate_metrics(y_true, y_pred, y_scaler):
    if y_true.ndim == 1:
        y_true = y_true.reshape(-1, 1)
    if y_pred.ndim == 1:
        y_pred = y_pred.reshape(-1, 1)
    
    y_true_unscaled = y_scaler.inverse_transform(y_true)
    y_pred_unscaled = y_scaler.inverse_transform(y_pred)
    
    r2 = r2_score(y_true_unscaled, y_pred_unscaled)
    mse = mean_squared_error(y_true_unscaled, y_pred_unscaled)
    mae = mean_absolute_error(y_true_unscaled, y_pred_unscaled)
    
    return r2, mse, mae

def run_base_models_with_tuning(X, y, n_estimators):
    base_models = [
            (GradientBoostingRegressor(), {
                'n_estimators': [n_estimators],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7]
            }),
            (RandomForestRegressor(), {
                'n_estimators': [n_estimators],
                'max_depth': [None, 10, 20],
                'min_samples_split': [2, 5, 10]
            }),
            (SVR(), {
                'C': [0.1, 1, 10],
                'kernel': ['rbf', 'linear'],
                'gamma': ['scale', 'auto']
            }),
            (Lasso(), {
                'alpha': [0.1, 1, 10],
                'max_iter': [1000, 5000]
            }),
            (ElasticNet(), {
                'alpha': [0.1, 1, 10],
                'l1_ratio': [0.1, 0.5, 0.9],
                'max_iter': [1000, 5000]
            })
    ]

    base_model_results = []
    best_base_models = []

    rskf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=RANDOM_SEED)

    for model, param_grid in base_models:
        model_name = model.__class__.__name__
        print(f"Tuning {model_name}...")

        cv_scores = {'r2': [], 'mse': [], 'mae': [], 'train_r2': [], 'train_mse': [], 'train_mae': []}

        for train_index, val_index in rskf.split(X):
            X_train, X_val = X.iloc[train_index], X.iloc[val_index]
            y_train, y_val = y.iloc[train_index], y.iloc[val_index]

            X_train_scaled, X_scaler = scale_columns_with_robust_scaler(X_train)
            X_val_scaled = X_scaler.transform(X_val)
            y_train_scaled, y_scaler = scale_columns_with_robust_scaler(y_train)
            y_val_scaled = y_scaler.transform(y_val)

            grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')
            grid_search.fit(X_train_scaled, y_train_scaled.ravel())

            best_model = grid_search.best_estimator_
            val_pred = best_model.predict(X_val_scaled)
            train_pred = best_model.predict(X_train_scaled)

            r2, mse, mae = calculate_metrics(y_val_scaled, val_pred, y_scaler)
            train_r2, train_mse, train_mae = calculate_metrics(y_train_scaled, train_pred, y_scaler)

            cv_scores['r2'].append(r2)
            cv_scores['mse'].append(mse)
            cv_scores['mae'].append(mae)
            cv_scores['train_r2'].append(train_r2)
            cv_scores['train_mse'].append(train_mse)
            cv_scores['train_mae'].append(train_mae)

        r2_mean, r2_ci_lower, r2_ci_upper = np.mean(cv_scores['r2']), *calculate_confidence_intervals(cv_scores['r2'])
        mse_mean, mse_ci_lower, mse_ci_upper = np.mean(cv_scores['mse']), *calculate_confidence_intervals(cv_scores['mse'])
        mae_mean, mae_ci_lower, mae_ci_upper = np.mean(cv_scores['mae']), *calculate_confidence_intervals(cv_scores['mae'])

        train_r2_mean, train_r2_ci_lower, train_r2_ci_upper = np.mean(cv_scores['train_r2']), *calculate_confidence_intervals(cv_scores['train_r2'])
        train_mse_mean, train_mse_ci_lower, train_mse_ci_upper = np.mean(cv_scores['train_mse']), *calculate_confidence_intervals(cv_scores['train_mse'])
        train_mae_mean, train_mae_ci_lower, train_mae_ci_upper = np.mean(cv_scores['train_mae']), *calculate_confidence_intervals(cv_scores['train_mae'])

        base_model_results.append({
            'Model': f"{model_name} (n={n_estimators})",
            'R-squared Validation': r2_mean,
            'MSE Validation': mse_mean,
            'MAE Validation': mae_mean,
            'Validation R-squared CI Lower': r2_ci_lower,
            'Validation R-squared CI Upper': r2_ci_upper,
            'Validation MSE CI Lower': mse_ci_lower,
            'Validation MSE CI Upper': mse_ci_upper,
            'Validation MAE CI Lower': mae_ci_lower,
            'Validation MAE CI Upper': mae_ci_upper,
            'Train R-squared': train_r2_mean,
            'Train MSE': train_mse_mean,
            'Train MAE': train_mae_mean,
            'Train R-squared CI Lower': train_r2_ci_lower,
            'Train R-squared CI Upper': train_r2_ci_upper,
            'Train MSE CI Lower': train_mse_ci_lower,
            'Train MSE CI Upper': train_mse_ci_upper,
            'Train MAE CI Lower': train_mae_ci_lower,
            'Train MAE CI Upper': train_mae_ci_upper
        })

        X_scaled, X_scaler = scale_columns_with_robust_scaler(X)
        y_scaled, y_scaler = scale_columns_with_robust_scaler(y)
        best_model.fit(X_scaled, y_scaled.ravel())
        best_base_models.append(best_model)

    return base_model_results, best_base_models, X_scaler, y_scaler

def run_models_with_feature_combinations(X, y, mandatory_features, optional_features):
    all_results = []
    best_meta_model = None
    best_mae = float('inf')
    
    # Ensure all mandatory features are in X
    for feature in mandatory_features:
        if feature not in X.columns:
            raise ValueError(f"Mandatory feature '{feature}' not found in dataset")
    
    # Generate all combinations of optional features
    for r in range(len(optional_features) + 1):
        for optional_combination in itertools.combinations(optional_features, r):
            current_features = mandatory_features + list(optional_combination)
            print(f"\nTrying feature combination: {current_features}")
            
            X_subset = X[current_features]
            
            estimator_counts = [1]
            
            for n_estimators in estimator_counts:
                print(f"\nRunning base models with {n_estimators} estimators...")
                base_model_results, best_base_models, X_scaler, y_scaler = run_base_models_with_tuning(X_subset, y, n_estimators)
                
                # Add feature combination information to base model results
                for result in base_model_results:
                    result['Features'] = ', '.join(current_features)
                    result['N Estimators'] = n_estimators
                
                all_results.extend(base_model_results)
                
                print(f"\nRunning meta model with {n_estimators} estimators...")
                stacking_result, meta_model = run_meta_model_with_tuning(X_subset, y, best_base_models, X_scaler, y_scaler)
                
                # Add feature combination information to the stacking result
                stacking_result['Features'] = ', '.join(current_features)
                stacking_result['N Estimators'] = n_estimators
                
                all_results.append(stacking_result)
                
                if stacking_result['MAE Validation'] < best_mae:
                    best_mae = stacking_result['MAE Validation']
                    best_meta_model = meta_model
                    best_X_scaler = X_scaler
                    best_y_scaler = y_scaler
                    best_features = current_features
    
    return all_results, best_meta_model, best_X_scaler, best_y_scaler, best_features


def run_multiple_times(X, y, mandatory_features, optional_features, num_runs=3):
    for run in range(1, num_runs + 1):
        print(f"\nStarting Run {run}")
        
        # Set a different random seed for each run
        set_global_random_seed(RANDOM_SEED + run)
        
        all_results, best_meta_model, best_X_scaler, best_y_scaler, best_features = run_models_with_feature_combinations(X, y, mandatory_features, optional_features)

        # Create DataFrame from all results
        df_results = pd.DataFrame(all_results)

        # Save results to CSV
        file_name = f"stacking_results_tuned_run_{run}.csv"
        df_results.to_csv(file_name, index=False)
        print(f"Results saved to {file_name}")

        # Save the best meta model
        model_file_name = f"best_stacking_ensemble_model_tuned_run_{run}.pkl"
        joblib.dump(best_meta_model, model_file_name)
        print(f"Best meta model saved as '{model_file_name}'")

        # Save the best scalers
        x_scaler_file_name = f"best_X_scaler_run_{run}.pkl"
        y_scaler_file_name = f"best_y_scaler_run_{run}.pkl"
        joblib.dump(best_X_scaler, x_scaler_file_name)
        joblib.dump(best_y_scaler, y_scaler_file_name)
        print(f"Best scalers saved as '{x_scaler_file_name}' and '{y_scaler_file_name}'")

        # Save the best features
        features_file_name = f"best_features_run_{run}.txt"
        with open(features_file_name, 'w') as f:
            f.write(', '.join(best_features))
        print(f"Best features saved as '{features_file_name}'")
        
        

# Main script
X = df[['Lignin (wt%)', 'Co-polyol (wt%)',
        'Co-polyol type (PTHF)', 'Isocyanate (wt%)', 
        'Isocyanate (mmol NCO)', 'Isocyanate type', 
        'Ratio', 'Tin(II) octoate','Swelling ratio (%)']]

y = df[['Tg (°C)']]

mandatory_features = ['Lignin (wt%)', 'Ratio', 'Co-polyol type (PTHF)']
optional_features = ['Co-polyol (wt%)', 'Isocyanate (wt%)', 'Isocyanate (mmol NCO)', 'Isocyanate type', 'Tin(II) octoate', 'Swelling ratio (%)']

# Run the process three times
run_multiple_times(X, y, mandatory_features, optional_features, num_runs=2)


